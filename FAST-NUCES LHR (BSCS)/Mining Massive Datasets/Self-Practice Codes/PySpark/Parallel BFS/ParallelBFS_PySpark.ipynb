{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Parallel BFS Code in PySpark - With Path Tracking**"
      ],
      "metadata": {
        "id": "KkY-nEyEI8sO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SINGLE-SOURCE SHORTEST PATH***"
      ],
      "metadata": {
        "id": "z4hcpCYYJs_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFISnFOyI3q4",
        "outputId": "cb161e93-847d-4352-f51d-a30c887ec58c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=77be91e8172b9661efaa9f873410083c70d9c4707ab9be892973d1173eb2df87\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Running on Colab\n",
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Importing Required Libraries\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Create Spark session and ContextRun PySpark.\n",
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\",\"4050\")\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.appName(\"DataFrame\").config('spark.ui.port', '4050').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "jPLadn4uJGgK",
        "outputId": "496c5875-3c74-4b8f-ef71-4e992102d564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7de11a90a8f0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6468cdcc763f:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textFile = sc.textFile(\"input.dat\")\n",
        "\n",
        "count = sc.accumulator(0)\n",
        "\n",
        "def customSplitNodesTextFile(node):\n",
        "\tif len(node.split(' ')) < 3:\n",
        "\t\tnid, distance = node.split(' ')\n",
        "\t\tneighbors = None\n",
        "\telse:\n",
        "\t\tnid, distance, neighbors = node.split(' ')\n",
        "\t\tneighbors = neighbors.split(':')\n",
        "\t\tneighbors = neighbors[:len(neighbors) - 1]\n",
        "\tpath = nid\n",
        "\treturn (nid , (int(distance), neighbors, path))\n",
        "\n",
        "def customSplitNodesIterative(node):\n",
        "\tnid = node[0]\n",
        "\tdistance = node[1][0]\n",
        "\tneighbors = node[1][1]\n",
        "\tpath = node[1][2]\n",
        "\telements = path.split('->')\n",
        "\tif elements[len(elements) - 1] != nid:\n",
        "\t\tpath = path + '->' + nid;\n",
        "\treturn (nid , (int(distance), neighbors, path))\n",
        "\n",
        "def customSplitNeighbor(parentPath, parentDistance, neighbor):\n",
        "\tif neighbor!=None:\n",
        "\t\tnid, distance = neighbor.split(',')\n",
        "\t\tdistance = parentDistance + int(distance)\n",
        "\t\tpath = parentPath + '->' + nid\n",
        "\t\treturn (nid, (int(distance), 'None', path))\n",
        "\n",
        "def minDistance(nodeValue1, nodeValue2):\n",
        "\tneighbors = None\n",
        "\tdistance = 0\n",
        "\tpath = ''\n",
        "\tif nodeValue1[1] != 'None':\n",
        "\t\tneighbors = nodeValue1[1]\n",
        "\telse:\n",
        "\t\tneighbors = nodeValue2[1]\n",
        "\tdist1 = nodeValue1[0]\n",
        "\tdist2 = nodeValue2[0]\n",
        "\tif dist1 <= dist2:\n",
        "\t\tdistance = dist1\n",
        "\t\tpath = nodeValue1[2]\n",
        "\telse:\n",
        "\t\tcount.add(1);\n",
        "\t\tdistance = dist2\n",
        "\t\tpath = nodeValue2[2]\n",
        "\treturn (distance, neighbors, path)\n",
        "\n",
        "def formatResult(node):\n",
        "\tnid = node[0]\n",
        "\tminDistance = node[1][0]\n",
        "\tpath = node[1][2]\n",
        "\treturn nid, minDistance, path\n",
        "\n",
        "nodes = textFile.map(lambda node: customSplitNodesTextFile(node))\n",
        "\n",
        "oldCount = 0\n",
        "iterations = 0\n",
        "while True:\n",
        "\titerations += 1\n",
        "\tnodesValues = nodes.map(lambda x: x[1])\n",
        "\tneighbors = nodesValues.filter(lambda nodeDataFilter: nodeDataFilter[1]!=None).map(\n",
        "\t\tlambda nodeData: map(\n",
        "\t\t\tlambda neighbor: customSplitNeighbor(\n",
        "\t\t\t\tnodeData[2], nodeData[0], neighbor\n",
        "\t\t\t), nodeData[1]\n",
        "\t\t)\n",
        "\t).flatMap(lambda x: x)\n",
        "\tmapper = nodes.union(neighbors)\n",
        "\treducer = mapper.reduceByKey(lambda x, y: minDistance(x, y))\n",
        "\tnodes = reducer.map(lambda node: customSplitNodesIterative(node))\n",
        "\tnodes.count() # We call the count to execute all the RDD transformations\n",
        "\tif oldCount == count.value:\n",
        "\t\tbreak\n",
        "\toldCount=count.value\n",
        "\n",
        "print('Finished after: ' + str(iterations) + ' iterations')\n",
        "result = reducer.map(lambda node: formatResult(node))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UHN1_fvKpck",
        "outputId": "c4461fe3-99b1-4afc-e059-725339b3237b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished after: 5 iterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsQZhsK0Lg6J",
        "outputId": "beaa5eb5-4f74-4fe4-fa5f-1996c8721775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('5', 7, '1->3->5'),\n",
              " ('2', 8, '1->3->2'),\n",
              " ('1', 0, '1'),\n",
              " ('3', 5, '1->3'),\n",
              " ('4', 9, '1->3->2->4')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My Own **Try**"
      ],
      "metadata": {
        "id": "vO52GF_yPUas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note 999 means Infinity\n",
        "# We have to store node name, distance from source, neigbours, neighbors edge weight, shortest path parent node\n",
        "nodes=sc.parallelize([('1',('0',['2,10','3,5'],'1')), #Initially, parent node equals to itself and distance from source node (except for source itself) infinity\n",
        "                      ('2',('999',['3,2','4,1'],'2')),\n",
        "                      ('3',('999',['2,3','4,9','5,2'],'3')),\n",
        "                      ('4',('999',['5,4'],'4')),\n",
        "                      ('5',('999',['1,7','4,6'],'5'))])\n",
        "nodes.collect()"
      ],
      "metadata": {
        "id": "gELD1nKiL07k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e00655a-16ef-48f5-e49e-36c9d26f1478"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', ('0', ['2,10', '3,5'], '1')),\n",
              " ('2', ('999', ['3,2', '4,1'], '2')),\n",
              " ('3', ('999', ['2,3', '4,9', '5,2'], '3')),\n",
              " ('4', ('999', ['5,4'], '4')),\n",
              " ('5', ('999', ['1,7', '4,6'], '5'))]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes.values().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDJnCukbQI5o",
        "outputId": "b143a9d0-c5b3-4777-afe1-cb4e207b2e68"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0', ['2,10', '3,5'], '1'),\n",
              " ('999', ['3,2', '4,1'], '2'),\n",
              " ('999', ['2,3', '4,9', '5,2'], '3'),\n",
              " ('999', ['5,4'], '4'),\n",
              " ('999', ['1,7', '4,6'], '5')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Algorithm is 4 steps\n",
        "#Step1 Use Map to get node values only i.e distance from source, neigbours, neighbors edge weight, shortest path parent node\n",
        "#Step2 Use flatMap to Seperate neigbours and edge weights\n",
        "#Step3 Take Union of org and step2 ans\n",
        "#Step4 Use Reduce By Key to Find Minimum Distance from source node\n",
        "\n",
        "nodes=sc.parallelize([('1',(0,['2,10','3,5'],'1')), #Initially, parent node equals to itself and distance from source node (except for source itself) infinity\n",
        "                      ('2',(999,['3,2','4,1'],'2')),\n",
        "                      ('3',(999,['2,3','4,9','5,2'],'3')),\n",
        "                      ('4',(999,['5,4'],'4')),\n",
        "                      ('5',(999,['1,7','4,6'],'5'))])\n",
        "# Step 1\n",
        "i=0\n",
        "\n",
        "#Function for Neighbour Split\n",
        "def NeighbourSplit(value):\n",
        "  answer=[]\n",
        "  dist,neighbours,parentNode = value\n",
        "  for neighbourInfo in neighbours:\n",
        "    neighbour,weight=neighbourInfo.split(',')\n",
        "    answer.append((neighbour,(int(weight)+int(dist),None,parentNode+'->'+neighbour)))\n",
        "  return answer\n",
        "\n",
        "def MinDistance(value,value2):\n",
        "  dist,structure,parentNode=value\n",
        "  dist2,structure2,parentNode2=value2\n",
        "  if(int(dist)<int(dist2)):\n",
        "    return (dist,structure if structure != 'None' else structure2,parentNode)\n",
        "  else:\n",
        "   return (dist2,structure if structure != 'None' else structure2,parentNode2)\n",
        "\n",
        "while i<4: #This should be while True but for testing Purposes keep i<4\n",
        "  nodeValues=nodes.map(lambda x:x[1]) # get all values using MAP\n",
        "  neighboursNode=nodeValues.flatMap(lambda value: NeighbourSplit(value))\n",
        "  allInformation=nodes.union(neighboursNode)\n",
        "  nodes=allInformation.reduceByKey(lambda x,y: MinDistance(x,y))\n",
        "  i=i+1\n",
        "\n",
        "nodes.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmOk4HVRPLZr",
        "outputId": "3e966ca0-01e7-4146-af01-448cc1195ddc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('5', (7, ['1,7', '4,6'], '1->3->5')),\n",
              " ('3', (5, ['2,3', '4,9', '5,2'], '1->3')),\n",
              " ('2', (8, ['3,2', '4,1'], '1->3->2')),\n",
              " ('4', (9, ['5,4'], '1->3->2->4')),\n",
              " ('1', (0, ['2,10', '3,5'], '1'))]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code with Accumulators used For Convergence"
      ],
      "metadata": {
        "id": "7JQN8kQXggAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Neighbour Split\n",
        "def NeighbourSplit(value):\n",
        "    dist, neighbours, parentNode = value\n",
        "    answer = []\n",
        "    if neighbours:\n",
        "        for neighbourInfo in neighbours:\n",
        "            neighbour, weight = neighbourInfo.split(',')\n",
        "            answer.append((neighbour, (int(weight) + int(dist), None, parentNode + '->' + neighbour)))\n",
        "    return answer\n",
        "\n",
        "# Function to find minimum distance and update accumulator\n",
        "def MinDistance(value1, value2):\n",
        "    dist1, structure1, parentNode1 = value1\n",
        "    dist2, structure2, parentNode2 = value2\n",
        "\n",
        "    if int(dist1) < int(dist2):\n",
        "        if int(dist2) != int(dist1):\n",
        "            count.add(1)  # Increment accumulator when a shorter path is found\n",
        "        return (dist1, structure1 if structure1 != 'None' else structure2, parentNode1)\n",
        "    else:\n",
        "        if int(dist1) != int(dist2):\n",
        "            count.add(1)  # Increment accumulator when a shorter path is found\n",
        "        return (dist2, structure1 if structure1 != 'None' else structure2, parentNode2)\n",
        "\n",
        "\n",
        "# Function to format result\n",
        "def formatResult(node):\n",
        "    nid = node[0]\n",
        "    minDistance = node[1][0]\n",
        "    path = node[1][2]\n",
        "    return nid, minDistance, path\n",
        "\n",
        "nodes = sc.parallelize([('1', (0, ['2,10', '3,5'], '1')),\n",
        "                        ('2', (999, ['3,2', '4,1'], '2')),\n",
        "                        ('3', (999, ['2,3', '4,9', '5,2'], '3')),\n",
        "                        ('4', (999, ['5,4'], '4')),\n",
        "                        ('5', (999, ['1,7', '4,6'], '5'))])\n",
        "\n",
        "count = sc.accumulator(0)\n",
        "oldCount = 0\n",
        "iterations = 0\n",
        "converged = False\n",
        "\n",
        "while not converged and iterations < 100:  # Large number for practical purposes\n",
        "    iterations += 1\n",
        "    count = sc.accumulator(0)\n",
        "\n",
        "    # Step 1: Get node values\n",
        "    nodeValues = nodes.map(lambda x: x[1])\n",
        "\n",
        "    # Step 2: Separate neighbours and edge weights\n",
        "    neighboursNode = nodeValues.flatMap(lambda value: NeighbourSplit(value))\n",
        "\n",
        "    # Step 3: Take union of original and neighbours\n",
        "    allInformation = nodes.union(neighboursNode)\n",
        "\n",
        "    # Step 4: Reduce by key to find minimum distance\n",
        "    nodes = allInformation.reduceByKey(lambda x, y: MinDistance(x, y))\n",
        "\n",
        "    # Trigger the execution of transformations\n",
        "    nodes.count()\n",
        "\n",
        "    # Check for convergence\n",
        "    if oldCount == count.value:\n",
        "        converged = True\n",
        "    else:\n",
        "        oldCount = count.value\n",
        "\n",
        "    print(f\"Iteration {iterations}: {count.value} updates\")\n",
        "\n",
        "print(f'Finished after: {iterations} iterations')\n",
        "result = nodes.map(lambda node: formatResult(node)).collect()\n",
        "print(result)\n",
        "#  By triggering execution, we can accurately update and check the value of the accumulator count.\n",
        "#  This value tells us if any updates were made in the current iteration, which is crucial for determining if the algorithm has converged."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQjkfpz1e3Zy",
        "outputId": "64ea9e41-18ed-467a-9ab0-92eb67657fad"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: 10 updates\n",
            "Iteration 2: 23 updates\n",
            "Iteration 3: 23 updates\n",
            "Finished after: 3 iterations\n",
            "[('4', 9, '1->3->2->4'), ('1', 0, '1'), ('5', 7, '1->3->5'), ('3', 5, '1->3'), ('2', 8, '1->3->2')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5B3OyBvUJa4",
        "outputId": "714c0c61-a7b0-47ab-f18c-86a9f5e32a38"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('4', (9, ['5,4'], '1->3->2->4')),\n",
              " ('1', (0, ['2,10', '3,5'], '1')),\n",
              " ('5', (7, ['1,7', '4,6'], '1->3->5')),\n",
              " ('3', (5, ['2,3', '4,9', '5,2'], '1->3')),\n",
              " ('2', (8, ['3,2', '4,1'], '1->3->2'))]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Manal's Code***"
      ],
      "metadata": {
        "id": "_4h6zQD2lbis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def splitNeighbours(parentPath,parentDist,neighbour):\n",
        "\n",
        "    nid, weight = neighbour.split(',')\n",
        "    dist = int(weight) + parentDist\n",
        "    path = parentPath + '->' + nid\n",
        "\n",
        "    return (nid, (dist,'None',path))\n",
        "\n",
        "\n",
        "\n",
        "def minDistance(x,y):\n",
        "    z = [0,0,0]\n",
        "\n",
        "    if x[0] < y[0]:\n",
        "        z[0] = x[0]\n",
        "        z[2] = x[2]\n",
        "\n",
        "    else:\n",
        "        z[0] = y[0]\n",
        "        z[2] = y[2]\n",
        "\n",
        "    if x[1] == 'None':\n",
        "        z[1] = y[1]\n",
        "\n",
        "    else:\n",
        "        z[1] = x[1]\n",
        "\n",
        "    return tuple(z)\n",
        "\n",
        "\n",
        "rdd1 = sc.parallelize([('1', (0,['2,10','3,5'],'1')),('2', (999,['3,2','4,1'],'2')),('3', (999,['2,3','4,9','5,2'],'3')),\n",
        "                    ('4', (999,['5,4'],'4')),('5', (999,['1,7','4,6'],'5'))])\n",
        "n = 0\n",
        "\n",
        "while n < 4 :\n",
        "\n",
        "    rdd2 = rdd1.map(lambda x: x[1])\n",
        "    rdd3 = rdd2.map(lambda nodeData: map(lambda neighbour: splitNeighbours(nodeData[2],nodeData[0],neighbour),nodeData[1])).flatMap(lambda x: x)\n",
        "    rdd4 = rdd1.union(rdd3)\n",
        "    rdd5 = rdd4.reduceByKey(lambda x,y: minDistance(x,y))\n",
        "    rdd1 = rdd5\n",
        "    n = n + 1\n",
        "\n",
        "rdd1.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSSoRdvHijW6",
        "outputId": "7bb5fed1-2a43-448f-ebfd-79843e270cd0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('5', (7, ['1,7', '4,6'], '1->3->5')),\n",
              " ('3', (5, ['2,3', '4,9', '5,2'], '1->3')),\n",
              " ('2', (8, ['3,2', '4,1'], '1->3->2')),\n",
              " ('4', (9, ['5,4'], '1->3->2->4')),\n",
              " ('1', (0, ['2,10', '3,5'], '1'))]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2xUvb6AnmDY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}